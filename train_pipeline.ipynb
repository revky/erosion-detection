{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffc492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from rasterio.plot import reshape_as_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SegmentDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 image_path: Path, \n",
    "                 mask_path: Path, \n",
    "                 patch_size: int):\n",
    "        super().__init__()\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.patch_size = patch_size\n",
    " \n",
    "        with rasterio.open(str(self.image_path), 'r', driver='JP2OpenJPEG') as src:\n",
    "                self.image_raster = src.read()\n",
    "\n",
    "        with rasterio.open(str(self.mask_path), 'r', driver='JP2OpenJPEG') as src:\n",
    "                self.mask_raster = src.read()\n",
    "\n",
    "        if self.image_raster[0].shape == self.mask_raster[0].shape:\n",
    "            self.width = self.image_raster.shape[1]\n",
    "            self.height = self.image_raster.shape[2]\n",
    "\n",
    "            self.images = self.make_patches(self.image_raster)\n",
    "            self.masks = self.make_patches(self.mask_raster)\n",
    "        \n",
    "    def make_patches(self, raster: np.array):\n",
    "        if self.patch_size is None:\n",
    "            raise ValueError('You must specify patch size.')\n",
    "            \n",
    "        slices = []    \n",
    "        for h_cord in np.arange(start=self.patch_size, \n",
    "                                stop=self.height + 1, \n",
    "                                step=self.patch_size):\n",
    "            for w_cord in np.arange(start=self.patch_size, \n",
    "                                    stop=self.width + 1, \n",
    "                                    step=self.patch_size):\n",
    "                slices.append(reshape_as_image(raster[:, \n",
    "                               h_cord - self.patch_size: h_cord, \n",
    "                               w_cord - self.patch_size: w_cord]))\n",
    "        return slices\n",
    "    \n",
    "    def save_patches(self, path_to_save:Path):\n",
    "        tqd = tqdm(enumerate(zip(self.images, self.masks), start = 1))\n",
    "        for i, (image, mask) in tqd:\n",
    "            img_path = (path_to_save / str(self.patch_size) / 'images')\n",
    "            img_path.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            mask_path = (path_to_save / str(self.patch_size) / 'masks')\n",
    "            mask_path.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            cv2.imwrite(str(img_path / f'{i}.jpg'), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "            cv2.imwrite(str(mask_path / f'{i}.jpg'), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a78284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path('data/raw/image.jp2')\n",
    "mask_path = Path('data/raw/mask.jp2')\n",
    "cashe_path = Path('data')\n",
    "dataset = SegmentDataset(image_path, mask_path, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2f83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443c6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
